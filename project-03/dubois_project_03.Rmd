---
title: "Visualizing Text and Distributions"
output: 
  html_document:
    keep_md: true
    toc: true
    toc_float: true
---

# Data Visualization Project 03


In this exercise you will explore methods to visualize text data and practice how to recreate charts that show the distributions of a continuous variable. 


## Part 1: Density Plots

Using the dataset obtained from FSU's [Florida Climate Center](https://climatecenter.fsu.edu/climate-data-access-tools/downloadable-data), for a station at Tampa International Airport (TPA) from 2016 to 2017, attempt to recreate the charts shown below

```{r, message=FALSE, warning=FALSE}
library(tidyverse)
library(RColorBrewer)
library(ggridges)
library(tidytext)
library(igraph)
library(ggraph)
weather_tpa <- read_csv("https://github.com/reisanar/datasets/raw/master/tpa_weather_16_17.csv")
# random sample 
sample_n(weather_tpa, 4)

color_scale = c("#440D54","#482073","#433E85","#38598C","#2D708E","#25858E","#1E9B8A","#2CB07F","#51C56A","#85D54A","#C2DF23","#FDE725")
```

(a)

```{r, echo = FALSE, out.width="80%", fig.align='center'}
cust_label <- setNames(month.name[unique(weather_tpa$month)],unique(weather_tpa$month))

ggplot(data = weather_tpa)+
  geom_histogram(aes(x=max_temp, fill=factor(month)), binwidth = 3, color="white")+
  theme_light()+
  scale_fill_manual(values = color_scale)+
  facet_wrap(~month, ncol = 4, labeller = as_labeller(cust_label))+
  labs(y="Number of Days",x="Maximum temperatures")+
  theme(legend.position="none")
  
```

(b)

```{r, echo = FALSE, out.width="80%", fig.align='center'}
ggplot(data = weather_tpa)+
  geom_density(aes(x=max_temp), kernel="epanechnikov", bw = 0.5, fill="#7F7F7F", size=1)+
  theme_light()+
  labs(y="density",x="Maximum temperature")+
  theme(legend.position="none")+
  theme(panel.border = element_blank())
```

(c)

```{r, echo = FALSE, out.width="80%", fig.align='center'}
cust_label <- setNames(month.name[unique(weather_tpa$month)],unique(weather_tpa$month))

ggplot(data = weather_tpa)+
  geom_density(aes(x=max_temp, fill = factor(month)), size=1, alpha=0.8)+
  theme_light()+
  scale_fill_manual(values = color_scale)+
  facet_wrap(~month, ncol = 4, labeller = as_labeller(cust_label))+
  labs(x="Maximum temperatures",y="",title="Density plots for each month in 2016")+
  theme(legend.position="none")
```

(d)

```{r, echo = FALSE, out.width="80%", fig.align='center', message=FALSE, warning=FALSE}
ggplot(data = weather_tpa)+
  geom_density_ridges(aes(x = max_temp, y = factor(month), fill=factor(month)),quantile_lines = TRUE, quantiles = 2, size=1)+
  theme_light()+
  labs(x="Maximum temperature",y="")+
  scale_fill_manual(values = color_scale)+
  theme(legend.position="none")+
  theme(panel.border = element_blank())+
  scale_y_discrete(labels=cust_label)
```

(e)

```{r, echo = FALSE, out.width="80%", fig.align='center', message=FALSE, warning=FALSE}
ggplot(data = weather_tpa)+
  geom_density_ridges(aes(x = max_temp, y = factor(month), fill=factor(month)),quantile_lines = TRUE, quantiles = 2, size=1)+
  theme_light()+
  labs(x="Maximum temperature",y="")+
  scale_fill_manual(values = color_scale)+
  theme(legend.position="none")+
  theme(panel.border = element_blank())+
  scale_y_discrete(labels=cust_label)
```

(f) 

```{r, echo = FALSE, out.width="80%", fig.align='center', message=FALSE, warning=FALSE}
ggplot(data = weather_tpa, aes(x = max_temp, y = factor(month), fill=stat(x)))+
  geom_density_ridges_gradient(quantile_lines = TRUE, quantiles = 2, size=1)+
  theme_light()+
  labs(x="Maximum temperature (in Fahrenheit degrees)",y="",fill="")+
  scale_fill_viridis_c(option = "plasma")+
  theme(legend.position="right")+
  theme(panel.border = element_blank())+
  scale_y_discrete(labels=cust_label)
```


## Part 2: Visualizing Text Data

The visualization below shows the various combinations of words in the Florida Poly News 2020 file, with edge node being a word and the edges being times the words were used together as a bigram. The size of the edge shows the frequencies. "Covid 19" is the most common bigram as we would expect for any news source in 2020.

```{r, echo = FALSE, message=FALSE, warning=FALSE}

poly_news <- read_csv("https://github.com/reisanar/datasets/raw/master/poly_news_FL20.csv")

poly_filtered <- poly_news %>%
    unnest_tokens(bigram, news_summary, token = "ngrams", n = 2) %>%
    separate(bigram, into = c("word1", "word2"), sep = " ") %>% 
    filter(!word1 %in% stop_words$word, !is.na(word1)) %>%
    filter(!word2 %in% stop_words$word, !is.na(word2)) %>%
    filter(!word1 == "florida" & !word2=="polytehcnic") %>%
    filter(!word1 == "polytechnic" & !word2=="university")

poly_counts <- poly_filtered %>% 
  count(word1, word2, sort = TRUE)

bigram_graph <- poly_counts %>%
  filter(n > 2) %>%
  graph_from_data_frame()

set.seed(100)
a <- grid::arrow(
  type = "closed", 
  length = unit(.10, "inches"))

ggraph(bigram_graph, layout = "fr") +
  geom_edge_link(aes(edge_width = n), color="grey", end_cap = circle(.07, 'inches')) +
  geom_node_point(color = "#4D338A", size = 6) +
  geom_node_text(aes(label = name), vjust = 1.5, hjust = 0.2) +
  theme_void()+
  theme(legend.position = "bottom")+
  labs(title="Bigrams in Florida Poly News 2020",edge_width="Occurances")
```

